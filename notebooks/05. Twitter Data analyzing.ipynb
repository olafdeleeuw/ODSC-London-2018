{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load words and vectors\n",
    "words = np.load('words.npy')\n",
    "words = words.tolist()\n",
    "vectors = np.load('vectors.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Tweet indices stored earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = np.load('tweet_indices.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict all our 1 million tweets\n",
    "We will make the prediction via batches with a batch size of 64. 1e6 Tweets, means about 15.625 iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First set parameters and restore the latest results from our trained Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 64                          # size of the batch you feed to your model every iteration\n",
    "pred_iterations = 15625\n",
    "max_length = 75                           # each tweet has a different length. However, RNN requires a fixed length.\n",
    "output_class = 2\n",
    "vector_dim = 50\n",
    "lstm_units = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/adam_bs64_lstm64_subset/trained_adam_bs64_lstm64_subset.ckpt-90000\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batch_size, output_class])\n",
    "input_data = tf.placeholder(tf.int32, [batch_size, max_length])\n",
    "\n",
    "data = tf.Variable(tf.zeros([batch_size, max_length, vector_dim]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(vectors,input_data)\n",
    "\n",
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(lstm_units)\n",
    "lstm_cell = tf.contrib.rnn.DropoutWrapper(cell=lstm_cell, output_keep_prob=0.25)\n",
    "value, _ = tf.nn.dynamic_rnn(lstm_cell, data, dtype=tf.float32)\n",
    "\n",
    "weight = tf.Variable(tf.truncated_normal([lstm_units, output_class]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[output_class]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('models/adam_bs64_lstm64_subset'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define batch function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TweetBatch(pred_iteration):\n",
    "    labels = []\n",
    "    indices = np.zeros([batch_size, max_length])\n",
    "    for i in range(batch_size):\n",
    "        j = pred_iteration * batch_size\n",
    "        k = i + j\n",
    "        labels.append([k,0])\n",
    "        indices[i] = tweets[k]\n",
    "    return indices, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run and store the predicitions\n",
    "preds_total_set = []\n",
    "for p in range(pred_iterations):\n",
    "    tweet, labels = TweetBatch(p)\n",
    "    preds_batch = (sess.run(prediction, {input_data: tweet}))\n",
    "    preds_total_set.append(preds_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is stored in a numpy array per iteration. We convert it to one array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_twitter = preds_total_set[0]\n",
    "for i in range(1,len(preds_total_set)):\n",
    "    prediction_batch = preds_total_set[i]\n",
    "    predictions_twitter = np.concatenate((predictions_twitter, prediction_batch), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions\n",
    "np.save(\"predictions_twitter\", predictions_twitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the sentiment of each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the first 10 tweets is: [0, 1, 1, 1, 0, 1, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "sentiment = []\n",
    "for p in range(0, len(predictions_twitter)):\n",
    "    max_pred = max(predictions_twitter[p])\n",
    "    if max_pred == predictions_twitter[p][0]:\n",
    "        prediction = 1\n",
    "    else:\n",
    "        prediction = 0\n",
    "    sentiment.append(prediction)\n",
    "# print(\"The predictions of this sample are:\", predictions)\n",
    "print(\"The sentiment of the first 10 tweets is:\", sentiment[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the list of sentiments with the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df with Twitter data\n",
    "twitter_df = pd.read_pickle(\"twitter_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>2018-01-22T09:31:41.357Z</td>\n",
       "      <td>\"Cryptocurrency Exchange OKCoin To Launch In S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>2018-01-22T09:31:41.363Z</td>\n",
       "      <td>\"RT @timothychou: Can an Algorithm Tell When K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>2018-01-22T09:31:41.855Z</td>\n",
       "      <td>\"RT @simdaq: Let's chat. Join us on Telegram a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>2018-01-22T09:31:42.362Z</td>\n",
       "      <td>\"RT @mas_oyama_coin: Masutatsu Oyama crypto cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>2018-01-22T09:30:59.854Z</td>\n",
       "      <td>\"U.S. Rating Agency to Issue Bitcoin and Crypt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dates                 timestamp  \\\n",
       "0  2018-01-22  2018-01-22T09:31:41.357Z   \n",
       "1  2018-01-22  2018-01-22T09:31:41.363Z   \n",
       "2  2018-01-22  2018-01-22T09:31:41.855Z   \n",
       "3  2018-01-22  2018-01-22T09:31:42.362Z   \n",
       "4  2018-01-22  2018-01-22T09:30:59.854Z   \n",
       "\n",
       "                                               tweet  \n",
       "0  \"Cryptocurrency Exchange OKCoin To Launch In S...  \n",
       "1  \"RT @timothychou: Can an Algorithm Tell When K...  \n",
       "2  \"RT @simdaq: Let's chat. Join us on Telegram a...  \n",
       "3  \"RT @mas_oyama_coin: Masutatsu Oyama crypto cu...  \n",
       "4  \"U.S. Rating Agency to Issue Bitcoin and Crypt...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = twitter_df['dates'][0:len(sentiment)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_per_day = pd.DataFrame({'dates': dates,\n",
    "                                'sentiment': sentiment})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dates  sentiment\n",
       "0  2018-01-22          0\n",
       "1  2018-01-22          1\n",
       "2  2018-01-22          1\n",
       "3  2018-01-22          1\n",
       "4  2018-01-22          0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_per_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe\n",
    "sentiment_per_day.to_pickle(\"sentiment_per_day\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
