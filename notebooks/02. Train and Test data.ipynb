{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. Load train and testdata\n",
    "To evaluate our collected Twitter data we need a trained model. Therefore we use an online available training and test set. The training data consists of 1.600.000 pre-evaluated tweets and can be downloaded from the Kaggle website: https://www.kaggle.com/kazanova/sentiment140. The set contains 1.6 million tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load words and vectors\n",
    "words = np.load('words.npy')\n",
    "words = words.tolist()\n",
    "vectors = np.load('vectors.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.load('wordsList-Copy1.npy')\n",
    "words = words.tolist() #Originally loaded as numpy array\n",
    "words = [word.decode('UTF-8') for word in words] #Encode words as UTF-8\n",
    "vectors = np.load('wordVectors-Copy1.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test and traindata\n",
    "data = pd.read_csv('/Users/olafdeleeuw/Desktop/ODSC/Project/ODSC-London-2018/data/data.csv', delimiter=',', quotechar='\"', encoding=\"ISO-8859-1\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000, 6)\n",
      "   0           1                             2         3                4  \\\n",
      "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
      "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
      "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
      "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
      "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
      "\n",
      "                                                   5  \n",
      "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
      "1  is upset that he can't update his Facebook by ...  \n",
      "2  @Kenichan I dived many times for the ball. Man...  \n",
      "3    my whole body feels itchy and like its on fire   \n",
      "4  @nationwideclass no, it's not behaving at all....  \n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store the labels\n",
    "\n",
    "To train the model we will use the label (positive or negative). These are in the first column of the dataframe where 4 is positive and 0 is negative. The labels will be stored as array [0,1] for a negative sentiment and [1,0] for a positive sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for l in range(0,len(data)):\n",
    "    if data[0].values[l] == 0:\n",
    "        label = [0, 1]\n",
    "    if data[0].values[l] == 4:\n",
    "        label = [1, 0]\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0           1                             2         3                4  \\\n",
       "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                                   5  labels  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  [0, 1]  \n",
       "1  is upset that he can't update his Facebook by ...  [0, 1]  \n",
       "2  @Kenichan I dived many times for the ball. Man...  [0, 1]  \n",
       "3    my whole body feels itchy and like its on fire   [0, 1]  \n",
       "4  @nationwideclass no, it's not behaving at all....  [0, 1]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data in a set with positive tweets and negative tweets. This is easier in the end when we need to get batches to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos = data[data[0].values == 4]\n",
    "data_neg = data[data[0].values == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "\n",
    "As always the data need to be cleaned. We remove the special characters and convert to lower characters. We use regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the text: remove special characters and convert to lower characters\n",
    "import re\n",
    "remove_chrs = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def clean_up_text(tweet):\n",
    "    tweet = tweet.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(remove_chrs, \"\", tweet.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned_tweets_pos = []\n",
    "for tweet in data_pos[5]:  # the tweet is in the 5th column of the dataframe\n",
    "    cleaned_tweet = clean_up_text(tweet)\n",
    "    data_cleaned_tweets_pos.append(cleaned_tweet)\n",
    "data_cleaned_tweets_neg = []\n",
    "for tweet in data_neg[5]:  # the tweet is in the 5th column of the dataframe\n",
    "    cleaned_tweet = clean_up_text(tweet)\n",
    "    data_cleaned_tweets_neg.append(cleaned_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the result of the cleaning on the first 10 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i love health4uandpets u guys r the best ', 'im meeting up with one of my besties tonight cant wait   girl talk', 'darealsunisakim thanks for the twitter add sunisa i got to meet you once at a hin show here in the dc area and you were a sweetheart ', 'being sick can be really cheap when it hurts too much to eat real food  plus your friends make you soup', 'lovesbrooklyn2 he has that effect on everyone ', 'productoffear you can tell him that i just burst out laughing really loud because of that  thanks for making me come out of my sulk', 'rkeithhill thans for your response ihad already find this answer ', 'keepinupwkris i am so jealous hope you had a great time in vegas how did you like the acms love your show ', 'tommcfly ah congrats mr fletcher for finally joining twitter ', 'e4voip i responded  stupid cat is helping me type forgive errors ']\n",
      "['switchfoot httptwitpiccom2y1zl  awww thats a bummer  you shoulda got david carr of third day to do it d', 'is upset that he cant update his facebook by texting it and might cry as a result  school today also blah', 'kenichan i dived many times for the ball managed to save 50  the rest go out of bounds', 'my whole body feels itchy and like its on fire ', 'nationwideclass no its not behaving at all im mad why am i here because i cant see you all over there ', 'kwesidei not the whole crew ', 'need a hug ', 'loltrish hey  long time no see yes rains a bit only a bit  lol  im fine thanks  hows you ', 'tatianak nope they didnt have it ', 'twittera que me muera  ']\n"
     ]
    }
   ],
   "source": [
    "print(data_cleaned_tweets_pos[0:10])\n",
    "print(data_cleaned_tweets_neg[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split them to lists\n",
    "\n",
    "This must be done to find the word indices and vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split_cleaned_pos = []\n",
    "for tweet_cleaned in data_cleaned_tweets_pos:\n",
    "    tweet_splitted = tweet_cleaned.split()\n",
    "    data_split_cleaned_pos.append(tweet_splitted)\n",
    "data_split_cleaned_neg = []\n",
    "for tweet_cleaned in data_cleaned_tweets_neg:\n",
    "    tweet_splitted = tweet_cleaned.split()\n",
    "    data_split_cleaned_neg.append(tweet_splitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for sentence in data_split_cleaned_pos:\n",
    "    length = len(sentence)\n",
    "    lengths.append(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the function as defined and explained in the previous notebook to get the word indices\n",
    "The maximum length of our tweets is about 41, maybe in another set a bit more. So to be on the safe side we create index vectors of length 75. The longer the vector, the longer it takes until a model is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_sentence_to_indices(sentence):\n",
    "    indices = np.zeros(75, dtype='int32')\n",
    "    for i in range(0,len(sentence)):\n",
    "        try:\n",
    "            indices[i] = words.index(sentence[i])\n",
    "        except:\n",
    "            indices[i] = 0\n",
    "    return(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split_word_indices_pos = []\n",
    "for tweet in data_split_cleaned_pos:\n",
    "    tweet_word_indices = turn_sentence_to_indices(tweet)\n",
    "    data_split_word_indices_pos.append(tweet_word_indices)\n",
    "data_split_word_indices_neg = []\n",
    "for tweet in data_split_cleaned_neg:\n",
    "    tweet_word_indices = turn_sentence_to_indices(tweet)\n",
    "    data_split_word_indices_neg.append(tweet_word_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split_word_indices_pos = np.asarray(data_split_word_indices_pos)\n",
    "data_split_word_indices_neg = np.asarray(data_split_word_indices_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the indices\n",
    "np.save(\"indices_pos_wl2\", data_split_word_indices_pos)\n",
    "np.save(\"indices_neg_wl2\", data_split_word_indices_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    41    835      0   6479   2284   1911 201534    254      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [ 14663    286     60     17     48      3    192      0   4385  52717\n",
      "    2472   1749   1077      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0   3124     10 201534  10360   1679      0     41    405      4\n",
      "     700     81    442     22      7  37655    273    187      6 201534\n",
      "    8038    237      5     81     35      7  21178      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [   134   4478     86     30    588   5115     61     20  11567    317\n",
      "     181      4   3623    567    565   2258    392   1095    159     81\n",
      "    8233      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0     18     31     12   1261     13   1402      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0     81     86   1361    103     12     41    120   6305     66\n",
      "    9674    588   6662    113      3     12   3124     10    433    285\n",
      "     326     66      3    192  94739      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0      0     10    392   1153      0    411    596     37   2168\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0     41    913    100  17095    824     81     40      7    353\n",
      "      79      6   4329    197    119     81    117 201534 190877    835\n",
      "     392    273      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0   3080 139302   6380   9637     10   1229   3242  10360      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0     41   3207   8979   5450     14   2116    285   1554  13339\n",
      "    5494      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]]\n",
      "[[107183      0 190100  86908      7  70483     81 107356    405    684\n",
      "    9912      3    245    122      4     88     20   1968      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [    14   3591     12     18  52717   4885     26   8320     21  41332\n",
      "      20      5    414   7033     19      7    712    164    373     52\n",
      "   26914      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0     41  17403    109    246     10 201534   1083   1764      4\n",
      "    1753    692 201534   1033    242     66      3  13910      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [   192   1115    719   3866  47660      5    117     47     13    484\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0     84     47     36  23437     22     64  14663   5121    738\n",
      "     913     41    187    113     41  52717    253     81     64     74\n",
      "      63      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0     36 201534   1115   1694      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [   408      7  16286      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0   7942    173     79     84    253   2772   6069      7   1594\n",
      "      91      7   1594  73048  14663   1695   3124 124291     81      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0  43895     39  93325     33     20      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]\n",
      " [     0   6967    285      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "# checkout the indices\n",
    "print(data_split_word_indices_pos[0:10])\n",
    "print(data_split_word_indices_neg[0:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
